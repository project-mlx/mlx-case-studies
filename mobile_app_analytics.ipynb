{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobile_app_analytics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfb6IYc1MDGikzbWyfDBu+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/project-mlx/mlx-projects-case-studies/blob/main/mobile_app_analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-3k7uf0GqPo"
      },
      "source": [
        "# Mobile App Analytics\n",
        "## App is available on https://share.streamlit.io/huzmorgoth/mobile-app-analytics/main.py \n",
        "- user acquisitions\n",
        "- user cohorts\n",
        "- event periods\n",
        "- Visualisations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTTsWgC1QDm3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPLZdgYsgP95"
      },
      "source": [
        "from plotly import graph_objs as go\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7N-VrNk8-hq"
      },
      "source": [
        "User acquisition class containing the required functions to calculate user acquisition, user cohort periods, and event periods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srvv2Oq-epmY"
      },
      "source": [
        "class UserAcquisition:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def user_acquisition(self, df, event):\n",
        "    \"\"\"\n",
        "     The function  for identifying the acquisition time for each user\n",
        "    \"\"\"\n",
        "    if not isinstance(df, pd.DataFrame):\n",
        "      raise TypeError('\"dataset\" needs to be a pandas dataframe')\n",
        "\n",
        "    if not isinstance(event, str):\n",
        "      raise TypeError('\"event\" needs to be a string')\n",
        "\n",
        "    if event not in df['event'].unique():\n",
        "      raise ValueError('\"event\" have to be a valid event present in the dataset')\n",
        "\n",
        "    # get the acquisition time for each user\n",
        "    acquisition = df[df['event'] == event].sort_values(\n",
        "        'time').drop_duplicates(\n",
        "            subset='user_id', keep='first')[['user_id', 'time']]\n",
        "\n",
        "    # convert df to a dictionary\n",
        "    acquisition = dict(zip(acquisition['user_id'], acquisition['time']))\n",
        "\n",
        "    return acquisition\n",
        "\n",
        "  def cohort_events_acquisition(self, df, event, period='week', month_format='period'):\n",
        "    \"\"\"\n",
        "    The function to add \"cohort\", \"event_period\", \"user_active\" and \"user_returns\" columns.\n",
        "    \"cohort\" is the weekly/monthly period that the user generated a successful plan (user acquired).\n",
        "    \"event_period\" is the cohort that any event belongs in.\n",
        "    \"user_active\" is True if the event took place at or after the user's acquisition time, False otherwise.\n",
        "    \"user_returns\" is True if the event took place during a period subsequent to the acquisition cohort,\n",
        "    False otherwise.\n",
        "    \"\"\"\n",
        "    assert period in ['day', 'week', 'month'], '\"period\" should be either \"day\", \"week\" or \"month\"'\n",
        "\n",
        "    if month_format:\n",
        "      assert month_format in ['period', 'datetime'], '\"month_format\" should be either \"period\" or \"datetime\"'\n",
        "\n",
        "    # user acquisition dictionary of unqiue acquired users\n",
        "    acquisition = self.user_acquisition(df, event)\n",
        "    users = acquisition.keys()\n",
        "\n",
        "    # filter dataframe for only acquired users\n",
        "    events = df[df['user_id'].isin(users)].copy()\n",
        "\n",
        "    # get acquisition time for each user and create a \"cohort\" column\n",
        "    events['acquisition_time'] = events['user_id'].map(acquisition)\n",
        "\n",
        "    # create the \"cohort\" and \"event_period\" columns, based on the period defined\n",
        "    if period == 'day':\n",
        "      events['cohort'] = events['acquisition_time'].dt.date\n",
        "      events['event_period'] = events['time'].dt.date\n",
        "\n",
        "    elif period == 'week':\n",
        "      events['cohort'] = (events['acquisition_time']\n",
        "                          - events['acquisition_time'].dt.weekday.astype(\n",
        "                              'timedelta64[D]')).astype('datetime64[D]')\n",
        "\n",
        "      events['event_period'] = (events['time']\n",
        "                                - events['time'].dt.weekday.astype(\n",
        "                                    'timedelta64[D]')).astype('datetime64[D]')\n",
        "\n",
        "    else:\n",
        "        # if monthly period, choose between pandas period type and datetime type\n",
        "        # period type has a nice monthly format and is fine for aggregations\n",
        "        # datetime would show up as first/last day of the month (yyyy-mm-dd)\n",
        "      if month_format == 'period':\n",
        "        events['cohort'] = events['acquisition_time'].dt.to_period('M')\n",
        "        events['event_period'] = events['time'].dt.to_period('M')\n",
        "\n",
        "      elif month_format == 'datetime':\n",
        "        events['cohort'] = events['acquisition_time'].dt.date.astype('datetime64[M]')\n",
        "        events['event_period'] = events['time'].dt.date.astype('datetime64[M]')\n",
        "\n",
        "    # indicate if the user did any action at or after his/her acquisition time\n",
        "    # if you do not want to count same-day activity replace following line with:\n",
        "    # events['user_active'] = (events['time'].dt.date > events['acquisition_time'].dt.date)\n",
        "    events['user_active'] = (events['time'] >= events['acquisition_time'])\n",
        "    events['plan_user_active'] = (events['time'] > events['acquisition_time'])\n",
        "\n",
        "    # indicate if the user returned in any period subsequent to his/her acquisition cohort\n",
        "    events['user_returns'] = (events['event_period'] > events['cohort'])\n",
        "\n",
        "    return events\n",
        "\n",
        "\n",
        "  def users_per_period(self, df, event, user_category, period='week', month_format='period'):\n",
        "    \"\"\"\n",
        "    The function to group new users into period cohorts.\n",
        "    The first time a user generates a plan is treated as the acquisition time.\n",
        "    \"\"\"\n",
        "    if user_category:\n",
        "      assert hasattr(df, user_category), '\"user_category\" needs to be a column in the df dataset'\n",
        "\n",
        "    # calculate the cohort for each user and period for each event\n",
        "    events = self.cohort_events_acquisition(df, event, period=period, month_format=month_format)\n",
        "\n",
        "    # will be used to rename the period column of each groupby result\n",
        "    period_name = {'week': 'week_starting',\n",
        "                  'month': \"month\"}\n",
        "\n",
        "    # calculate size of each users cohort\n",
        "    new_users = events.drop_duplicates(subset=['user_id', 'cohort']) \\\n",
        "        .groupby(['cohort']).size() \\\n",
        "        .reset_index() \\\n",
        "        .rename({0: 'new_users', 'cohort': period_name[period]}, axis=1) \\\n",
        "        .set_index(period_name[period])\n",
        "\n",
        "    # break down new users into Organic/Non-organic\n",
        "    if user_category:\n",
        "      category = events[events['event'] == event] \\\n",
        "          .groupby(['cohort', 'user_category'])['user_id'].nunique() \\\n",
        "          .reset_index() \\\n",
        "          .rename({'user_id': 'new_users', 'cohort': period_name[period]}, axis=1) \\\n",
        "          .set_index(period_name[period])\n",
        "\n",
        "      category = category.pivot(columns='user_category', values='new_users')[['organic', 'non-organic']] \\\n",
        "          .rename({'organic': 'new_organic_users', 'non-organic': 'new_non_organic_users'}, axis=1)\n",
        "\n",
        "    # calculate number of active users per period\n",
        "    active_users = events[events['user_active']] \\\n",
        "        .groupby(['event_period'])['user_id'].nunique() \\\n",
        "        .reset_index() \\\n",
        "        .rename({'user_id': 'active_users', 'event_period': period_name[period]}, axis=1) \\\n",
        "        .set_index(period_name[period])\n",
        "\n",
        "    # calculate number of returning users per period\n",
        "    returning_users = events[events['user_returns']] \\\n",
        "        .groupby(['event_period'])['user_id'].nunique() \\\n",
        "        .reset_index() \\\n",
        "        .rename({'user_id': 'returning_users', 'event_period': period_name[period]}, axis=1) \\\n",
        "        .set_index(period_name[period])\n",
        "\n",
        "    # merge into a single dataframe\n",
        "    if user_category:\n",
        "      ds = new_users.join([category, active_users, returning_users], how='outer', sort=False).astype('Int64').copy()\n",
        "    else:\n",
        "      ds = new_users.join([active_users, returning_users], how='outer', sort=False).astype('Int64').copy()\n",
        "    ds.fillna(0, inplace=True)\n",
        "\n",
        "    # calculate period-on-period growth\n",
        "    ds['w/w_growth'] = ds['new_users'].pct_change().apply(lambda x: \"{0:.2f}%\".format(x * 100))\n",
        "    ds['new/return_ratio'] = (ds['new_users'] / ds['returning_users']) \\\n",
        "        .fillna(0) \\\n",
        "        .replace(np.inf, np.nan) \\\n",
        "        .apply(lambda x: \"{0:.1f}\".format(x))\n",
        "\n",
        "    return ds\n",
        "\n",
        "  def create_funnel_df(self, df, steps, from_date=None, to_date=None, step_interval=0):\n",
        "    \"\"\"\n",
        "    Function used to create a dataframe that can be passed to functions for generating funnel plots\n",
        "    \"\"\"\n",
        "    assert isinstance(steps, list), '\"steps\" should be a list of strings'\n",
        "\n",
        "    if step_interval != 0:\n",
        "      assert isinstance(step_interval, pd.Timedelta), \\\n",
        "          '\"step_interval\" should be a valid pd.Timedelta object. For more info visit:' \\\n",
        "          'https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Timedelta.html'\n",
        "\n",
        "    # filter df for only events in the steps list\n",
        "    df = df[['user_id', 'event', 'time']]\n",
        "    df = df[df['event'].isin(steps)]\n",
        "\n",
        "    values = []\n",
        "    # create a dict to hold the filtered dataframe of each step\n",
        "    dfs = {}\n",
        "    # for each step, create a df and filter only for that step\n",
        "    for i, step in enumerate(steps):\n",
        "      if i == 0:\n",
        "\n",
        "          # filter for users that did the 1st event and find the minimum time\n",
        "        dfs[step] = df[df['event'] == step] \\\n",
        "            .sort_values(['user_id', 'time'], ascending=True) \\\n",
        "            .drop_duplicates(subset=['user_id', 'event'], keep='first')\n",
        "\n",
        "        # filter df of 1st step according to dates\n",
        "        # this will allow the 1st step to have started during the defined period\n",
        "        # but subsequent steps are allowed to occur at a later date so that the funnel\n",
        "        # is not penalised unfairly\n",
        "        if from_date:\n",
        "          dfs[step] = dfs[step][(dfs[step]['time'] >= from_date)]\n",
        "\n",
        "        if to_date:\n",
        "          dfs[step] = dfs[step][(dfs[step]['time'] <= to_date)]\n",
        "\n",
        "      else:\n",
        "          # filter for specific event\n",
        "        dfs[step] = df[df['event'] == step]\n",
        "\n",
        "        # left join with previous step\n",
        "        # this ensures only rows for which the distinct_ids appear in the previous step\n",
        "        merged = pd.merge(dfs[steps[i - 1]], dfs[step], on='user_id', how='left')\n",
        "\n",
        "        # keep only events that happened after previous step and sort by time\n",
        "        merged = merged[merged['time_y'] >=\n",
        "                        (merged['time_x'] + step_interval)].sort_values('time_y', ascending=True)\n",
        "\n",
        "        # take the minimum time of the valid ones for each user\n",
        "        merged = merged.drop_duplicates(subset=['user_id', 'event_x', 'event_y'], keep='first')\n",
        "\n",
        "        # keep only the necessary columns and rename them to match the original structure\n",
        "        merged = merged[['user_id', 'event_y', 'time_y']].rename({'event_y': 'event',\n",
        "                                                                      'time_y': 'time'}, axis=1)\n",
        "\n",
        "        # include the df in the df dictionary so that it can be joined to the next step's df\n",
        "        dfs[step] = merged\n",
        "\n",
        "        # append number of users to the \"values\" list\n",
        "      values.append(len(dfs[step]))\n",
        "\n",
        "    # create dataframe\n",
        "    funnel_df = pd.DataFrame({'step': steps, 'val': values})\n",
        "\n",
        "    return funnel_df\n",
        "\n",
        "\n",
        "  def group_funnel_dfs(self, df, steps, column):\n",
        "    \"\"\"\n",
        "    Function used to create a dict of funnel dataframes used to generate a stacked funnel plot\n",
        "    \"\"\"\n",
        "    assert isinstance(df, pd.DataFrame), '\"df\" should be a pandas dataframe'\n",
        "    assert isinstance(column, str), '\"col\" should be a string'\n",
        "    assert hasattr(df, column), '\"column\" should be a column in \"df\"'\n",
        "\n",
        "    dict_ = {}\n",
        "    # get the distinct_ids for each property that we are grouping by\n",
        "    ids = dict(df.groupby([column])['user_id'].apply(set))\n",
        "\n",
        "    for i in df[column].dropna().unique():\n",
        "      ids_list = ids[i]\n",
        "      df = df[df['user_id'].isin(ids_list)].copy()\n",
        "      if len(df[df['name'] == steps[0]]) > 0:\n",
        "        dict_[i] = self.create_funnel_df(df, steps)\n",
        "\n",
        "    return dict_\n",
        "\n",
        "  def cohort_period(self, df):\n",
        "    \"\"\"\n",
        "    Creates a `cohort_period` column, which is the Nth period based on the user's acquisition date.\n",
        "    \"\"\"\n",
        "    df['cohort_period'] = np.arange(len(df))\n",
        "    return df\n",
        "\n",
        "\n",
        "  def mask_retention_table(self, dim):\n",
        "    \"\"\"\n",
        "    Function used to fill NaN values with 0 above the diagonal line of the retention table and force\n",
        "    the rest to be NaN.\n",
        "    \"\"\"\n",
        "    # create an array of the same shape as the df and assign all elements =True\n",
        "    mask = np.full(dim, True)\n",
        "\n",
        "    # assign False where period for each row would no exist\n",
        "    # i.e. if we have 10 weeks, the 1st week would have data for the next 9 weeks but the 2nd week would\n",
        "    # only have data for the next 8 weeks, etc...\n",
        "    for row in range(mask.shape[0]):\n",
        "      mask[row, :mask.shape[0] - row] = False\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "  def retention_table(self, df, period='week', month_format='period', event_filter=None):\n",
        "    \"\"\"\n",
        "    Function used to generate retention stats split into weekly cohorts\n",
        "    \"\"\"\n",
        "    assert period in ['week', 'month'], '\"period\" should be either \"week\" or \"month\"'\n",
        "    if event_filter:\n",
        "      assert event_filter in df['event'].unique(), '\"event_filter\" should be a valid event present in \"df\"'\n",
        "\n",
        "    # filter out internal testers and get acquisition time of each user\n",
        "    # create an event_period column for each event\n",
        "    # determine if each event happened at least 1 day after the user acquisition\n",
        "    events = self.cohort_events_acquisition(df, period=period, month_format=month_format)\n",
        "\n",
        "    # calculate size of each users cohort\n",
        "    cohort_sizes = events.drop_duplicates(subset=['user_id', 'cohort']).cohort.value_counts() \\\n",
        "        .to_frame() \\\n",
        "        .rename({'cohort': 'size'}, axis=1)\n",
        "    cohort_sizes.index.rename('cohort', inplace=True)\n",
        "\n",
        "    # filter only for events after acquisition date\n",
        "    events = events[events['plan_user_active']]\n",
        "    # filter for event of interest\n",
        "    if event_filter:\n",
        "      events = events[events['event'] == event_filter]\n",
        "\n",
        "    grouped = events.groupby(['cohort', 'event_period'])\n",
        "\n",
        "    # count the unique users per Group + Period\n",
        "    cohorts = grouped.agg({'user_id': pd.Series.nunique})\n",
        "    # reindex the \"cohort\" (and \"event_period\" columns) to avoid empty weeks causing misalignment\n",
        "    # grab the minimum 'cohort' date and maximum 'event_period' date\n",
        "    start, end = cohorts.index.get_level_values('cohort').min(), \\\n",
        "                cohorts.index.get_level_values('event_period').max()\n",
        "\n",
        "    # TODO: if more periods will be considered need to add more here\n",
        "    if period == 'week':\n",
        "      full_index = pd.date_range(start=start, end=end, freq='W-MON', name='cohort')\n",
        "    elif period == 'month':\n",
        "      if month_format == 'period':\n",
        "        full_index = pd.date_range(start=start.to_timestamp(), end=end.to_timestamp(), freq='MS')\n",
        "      elif month_format == 'datetime':\n",
        "        full_index = pd.date_range(start=start, end=end, freq='MS')\n",
        "    cohorts.reset_index(inplace=True)\n",
        "\n",
        "    # create all possible combinations of possible date periods\n",
        "    # date_period needs to be equal to or greater than cohort\n",
        "    possible_dates = []\n",
        "    for i in range(len(full_index)):\n",
        "      for j in range(len(full_index)):\n",
        "        if i <= j:\n",
        "          possible_dates.append((i, j))\n",
        "\n",
        "    # fill in missing combinations of cohort and event_period\n",
        "    # add a new row in the df for a combination of possible dates with value=0\n",
        "    for combo in possible_dates:\n",
        "      if len(cohorts[(cohorts['cohort'] == full_index[combo[0]]) &\n",
        "                    (cohorts['event_period'] == full_index[combo[1]])]) < 1:\n",
        "        cohorts = cohorts.append({'cohort': full_index[combo[0]],\n",
        "                                  'event_period': full_index[combo[1]],\n",
        "                                  'user_id': 0},\n",
        "                                ignore_index=True) \\\n",
        "            .sort_values(['cohort', 'event_period'])\n",
        "    cohorts = cohorts.set_index(['cohort', 'event_period'])\n",
        "\n",
        "    # create 'cohort_period' column\n",
        "    cohorts = cohorts.astype(str).groupby(level=0).apply(self.cohort_period)\n",
        "\n",
        "    # reindex the DataFrame\n",
        "    cohorts.reset_index(inplace=True)\n",
        "    cohorts.set_index(['cohort', 'cohort_period'], inplace=True)\n",
        "\n",
        "    # create user_retention df\n",
        "    user_retention = cohorts['user_id'].unstack(0).T\n",
        "    # include the cohort size as a secondary index\n",
        "    user_retention = user_retention.join(cohort_sizes, how='outer', sort=False)\n",
        "    user_retention['size'].fillna(0, inplace=True)\n",
        "    user_retention['size'] = user_retention['size'].astype(int)\n",
        "    user_retention.set_index('size', append=True, inplace=True)\n",
        "    user_retention.columns.name = 'cohort_period'\n",
        "    # convert float to Int64\n",
        "    user_retention = user_retention[user_retention.columns].replace('NaN', np.NaN) \\\n",
        "        .astype('float64')\n",
        "    # .astype('Int64')\n",
        "\n",
        "    # convert to percentages\n",
        "    user_retention_pct = user_retention.divide(user_retention.index.get_level_values('size'), axis='rows')\n",
        "\n",
        "    # fill NaNs with 0 where a value is possible to exist\n",
        "    mask_array = self.mask_retention_table(user_retention.shape)\n",
        "    user_retention = user_retention.fillna(0).mask(mask_array)\n",
        "    user_retention_pct = user_retention_pct.fillna(0).mask(mask_array)\n",
        "\n",
        "    return user_retention, user_retention_pct\n",
        "\n",
        "  def filter_starting_step(self, x, starting_step, n_steps):\n",
        "    \"\"\"\n",
        "    Function used to return the first n_steps for each user starting from the \"starting_step\".\n",
        "    The function will be used to generate the event sequence journey for each user.\n",
        "    \"\"\"\n",
        "    assert isinstance(x, (list, pd.Series)), '\"x\" should be a python list or pandas series containing event names'\n",
        "    assert isinstance(starting_step, str), '\"starting_step\" should be a string resembling an event name'\n",
        "    assert isinstance(n_steps, int), '\"n_steps\" should be an integer'\n",
        "\n",
        "    starting_step_index = x.index(starting_step)\n",
        "\n",
        "    return x[starting_step_index: starting_step_index + n_steps]\n",
        "\n",
        "\n",
        "  def user_journey(self, df, starting_step, n_steps=3, events_per_step=5):\n",
        "    \"\"\"\n",
        "    Function used to map out the journey for each user starting from the defined \"starting_step\" and count\n",
        "    how many identical journeys exist across users.\n",
        "    \"\"\"\n",
        "    if not isinstance(df, pd.DataFrame):\n",
        "      raise TypeError('\"df\" should be a dataframe')\n",
        "\n",
        "    assert isinstance(events_per_step, int), '\"events_per_step\" should be an integer'\n",
        "    if events_per_step < 1:\n",
        "      raise ValueError('\"events_per_step\" should be equal or greater than 1')\n",
        "\n",
        "    # sort df by time\n",
        "    df = df.sort_values(['user_id', 'time'])\n",
        "    # find the users that have performed the starting_step\n",
        "    valid_ids = df[df['event'] == starting_step]['user_id'].unique()\n",
        "\n",
        "    # plan out the journey per user, with each step in a separate column\n",
        "    flow = df[(df['user_id'].isin(valid_ids))] \\\n",
        "        .groupby('user_id') \\\n",
        "        .name.agg(list) \\\n",
        "        .to_frame()['event'] \\\n",
        "        .apply(lambda x: self.filter_starting_step(x, starting_step=starting_step, n_steps=n_steps)) \\\n",
        "        .to_frame() \\\n",
        "        ['event'].apply(pd.Series)\n",
        "\n",
        "    # fill NaNs with \"End\" to denote no further step by user; this will be filtered out later\n",
        "    flow = flow.fillna('End')\n",
        "\n",
        "    # add the step number as prefix to each step\n",
        "    for i, col in enumerate(flow.columns):\n",
        "      flow[col] = '{}: '.format(i + 1) + flow[col].astype(str)\n",
        "\n",
        "    # replace events not in the top \"events_per_step\" most frequent list with the name \"Other\"\n",
        "    # this is done to avoid having too many nodes in the sankey diagram\n",
        "    for col in flow.columns:\n",
        "      all_events = flow[col].value_counts().index.tolist()\n",
        "      all_events = [e for e in all_events if e != (str(col + 1) + ': End')]\n",
        "      top_events = all_events[:events_per_step]\n",
        "      to_replace = list(set(all_events) - set(top_events))\n",
        "      flow[col].replace(to_replace, [str(col + 1) + ': Other'] * len(to_replace), inplace=True)\n",
        "\n",
        "    # count the number of identical journeys up the max step defined\n",
        "    flow = flow.groupby(list(range(n_steps))) \\\n",
        "        .size() \\\n",
        "        .to_frame() \\\n",
        "        .rename({0: 'count'}, axis=1) \\\n",
        "        .reset_index()\n",
        "\n",
        "    return flow\n",
        "\n",
        "\n",
        "  def sankey_df(self, df, starting_step, n_steps=3, events_per_step=5):\n",
        "    \"\"\"\n",
        "    Function used to generate the dataframe needed to be passed to the sankey generation function.\n",
        "    \"source\" and \"target\" column pairs denote links that will be shown in the sankey diagram.\n",
        "    \"\"\"\n",
        "    # generate the user user flow dataframe\n",
        "    flow = self.user_journey(df, starting_step, n_steps, events_per_step)\n",
        "\n",
        "    # create the nodes labels list\n",
        "    label_list = []\n",
        "    cat_cols = flow.columns[:-1].values.tolist()\n",
        "    for cat_col in cat_cols:\n",
        "      label_list_temp = list(set(flow[cat_col].values))\n",
        "      label_list = label_list + label_list_temp\n",
        "\n",
        "    # create a list of colours for the nodes\n",
        "    # assign 'blue' to any node and 'grey' to \"Other\" nodes\n",
        "    colors_list = ['blue' if i.find('Other') < 0 else 'grey' for i in label_list]\n",
        "\n",
        "    # transform flow df into a source-target pair\n",
        "    for i in range(len(cat_cols) - 1):\n",
        "      if i == 0:\n",
        "        source_target_df = flow[[cat_cols[i], cat_cols[i + 1], 'count']]\n",
        "        source_target_df.columns = ['source', 'target', 'count']\n",
        "      else:\n",
        "        temp_df = flow[[cat_cols[i], cat_cols[i + 1], 'count']]\n",
        "        temp_df.columns = ['source', 'target', 'count']\n",
        "        source_target_df = pd.concat([source_target_df, temp_df])\n",
        "      source_target_df = source_target_df.groupby(['source', 'target']).agg({'count': 'sum'}).reset_index()\n",
        "\n",
        "    # add index for source-target pair\n",
        "    source_target_df['source_id'] = source_target_df['source'].apply(lambda x: label_list.index(x))\n",
        "    source_target_df['target_id'] = source_target_df['target'].apply(lambda x: label_list.index(x))\n",
        "\n",
        "    # filter out the end step\n",
        "    source_target_df = source_target_df[(~source_target_df['source'].str.contains('End')) &\n",
        "                                        (~source_target_df['target'].str.contains('End'))]\n",
        "\n",
        "    return label_list, colors_list, source_target_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tat8L4a6QaVR"
      },
      "source": [
        "Generate dummy dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cbCCI2oHtrM"
      },
      "source": [
        "class Visualisations:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def plot_stacked_funnel(self, df, steps, col=None, from_date=None, to_date=None, step_interval=0):\n",
        "    \"\"\"\n",
        "    Function used for producing a funnel plot\n",
        "    \"\"\"\n",
        "\n",
        "    # create list to append each trace to\n",
        "    # this will be passed to \"go.Figure\" at the end\n",
        "    data = []\n",
        "\n",
        "    # if col is provided, create a funnel_df for each entry in the \"col\"\n",
        "    if col:\n",
        "        # generate dict of funnel dataframes\n",
        "      dict_ = acquisition_class.group_funnel_dfs(df, steps, col)\n",
        "      title = 'Funnel plot per {}'.format(col)\n",
        "    else:\n",
        "      funnel_df = acquisition_class.create_funnel_df(df, steps, from_date=from_date, to_date=to_date, step_interval=step_interval)\n",
        "      dict_ = {'Total': funnel_df}\n",
        "      title = 'Funnel plot'\n",
        "\n",
        "    for t in dict_.keys():\n",
        "      trace = go.Funnel(\n",
        "          name=t,\n",
        "          y=dict_[t].step.values,\n",
        "          x=dict_[t].val.values,\n",
        "          textinfo=\"value+percent previous\"\n",
        "      )\n",
        "      data.append(trace)\n",
        "\n",
        "    layout = go.Layout(margin={\"l\": 180, \"r\": 0, \"t\": 30, \"b\": 0, \"pad\": 0},\n",
        "                       funnelmode=\"stack\",\n",
        "                       showlegend=True,\n",
        "                       hovermode='closest',\n",
        "                       title='Funnel plot per {}'.format(col),\n",
        "                       legend=dict(orientation=\"v\",\n",
        "                                   bgcolor='#E2E2E2',\n",
        "                                   xanchor='left',\n",
        "                                   font=dict(\n",
        "                                       size=12)\n",
        "                                   )\n",
        "                       )\n",
        "\n",
        "    return go.Figure(data, layout)\n",
        "\n",
        "  def growth(self, df, event, user_category, period='week'):\n",
        "    \"\"\"\n",
        "    Function use to create multi-axes plot and table for all the stats generated by\n",
        "    \"stats.retention.users_per_period\"\n",
        "    \"\"\"\n",
        "\n",
        "    # generate user stats per period\n",
        "    df = acquisition_class.users_per_period(df, event, user_category, period)\n",
        "\n",
        "    # needed to convert the month period to time_manipulations\n",
        "    if period == 'month':\n",
        "        df.index = df.index.to_timestamp().strftime(\"%Y-%m\")\n",
        "\n",
        "    # new users\n",
        "    new1 = go.Bar(\n",
        "        x=df.index,\n",
        "        y=df['new_users'].values,\n",
        "        text=df['new_users'].values,\n",
        "        textposition='auto',\n",
        "        marker=dict(\n",
        "            color='rgb(0,0,204)'),\n",
        "        name='New Users (total)',\n",
        "        xaxis='x1',\n",
        "        yaxis='y1'\n",
        "    )\n",
        "\n",
        "    # new users for 2nd axis\n",
        "    new2 = go.Bar(\n",
        "        x=df.index,\n",
        "        y=df['new_users'].values,\n",
        "        text=df['new_users'].values,\n",
        "        textposition='auto',\n",
        "        marker=dict(\n",
        "            color='rgb(0,0,204)'),\n",
        "        name='New Users (total)',\n",
        "        xaxis='x1',\n",
        "        yaxis='y2'\n",
        "    )\n",
        "\n",
        "    # organic users\n",
        "    organic = go.Bar(\n",
        "        x=df.index,\n",
        "        y=df['new_organic_users'].values,\n",
        "        text=df['new_organic_users'].values,\n",
        "        textposition='auto',\n",
        "        xaxis='x1',\n",
        "        yaxis='y1',\n",
        "        marker=dict(\n",
        "            color='rgb(58,193,0)'),\n",
        "        name='New Organic Users'\n",
        "    )\n",
        "\n",
        "    # paid users\n",
        "    non_organic = go.Bar(\n",
        "        x=df.index,\n",
        "        y=df['new_non_organic_users'].values,\n",
        "        text=df['new_non_organic_users'].values,\n",
        "        textposition='auto',\n",
        "        xaxis='x1',\n",
        "        yaxis='y1',\n",
        "        marker=dict(\n",
        "            color='rgb(255,0,0)'),\n",
        "        name='New Non-organic Users'\n",
        "    )\n",
        "\n",
        "    # active users\n",
        "    active = go.Bar(\n",
        "        x=df.index,\n",
        "        y=df['active_users'].values,\n",
        "        text=df['active_users'].values,\n",
        "        textposition='auto',\n",
        "        name='Active Users',\n",
        "        xaxis='x1',\n",
        "        yaxis='y2',\n",
        "        marker=dict(\n",
        "            color='rgb(153,0,76)')\n",
        "    )\n",
        "\n",
        "    # returning users\n",
        "    returning = go.Bar(\n",
        "        x=df.index,\n",
        "        y=df['returning_users'].values,\n",
        "        text=df['returning_users'].values,\n",
        "        textposition='auto',\n",
        "        name='Returning Users',\n",
        "        xaxis='x1',\n",
        "        yaxis='y2',\n",
        "        marker=dict(\n",
        "            color='rgb(255,128,0)')\n",
        "    )\n",
        "\n",
        "    # periodic growth\n",
        "    growth = go.Scatter(\n",
        "        x=df.index,\n",
        "        y=df['w/w_growth'].values,\n",
        "        name='period-on-period Growth',\n",
        "        xaxis='x1',\n",
        "        yaxis='y3',\n",
        "        marker=dict(\n",
        "            color='rgb(0,153,153)')\n",
        "    )\n",
        "\n",
        "    # NR ratio\n",
        "    NR_ratio = go.Scatter(\n",
        "        x=df.index,\n",
        "        y=df['new/return_ratio'].values,\n",
        "        name='New:Returning Ratio',\n",
        "        xaxis='x1',\n",
        "        yaxis='y4',\n",
        "        marker=dict(\n",
        "            color='rgb(192,192,192)')\n",
        "    )\n",
        "\n",
        "    # axis object\n",
        "    axis = dict(\n",
        "        showline=True,\n",
        "        zeroline=False,\n",
        "        showgrid=True,\n",
        "        ticklen=4,\n",
        "        gridcolor='#ffffff',\n",
        "        tickfont=dict(size=10),\n",
        "        linecolor='black',\n",
        "        linewidth=1\n",
        "    )\n",
        "\n",
        "    layout = dict(\n",
        "        width=950,\n",
        "        height=800,\n",
        "        autosize=True,\n",
        "        barmode='group',\n",
        "        margin={\"l\": 100, \"r\": 0, \"t\": 10, \"b\": 0, \"pad\": 0},\n",
        "        showlegend=True,\n",
        "        xaxis1=dict(axis, **dict(domain=[0, 1], anchor='y1', showticklabels=True,\n",
        "                                 ticktext=df.index,\n",
        "                                 tickvals=df.index,\n",
        "                                 tickangle=-45),\n",
        "                    rangeselector=dict(\n",
        "                        buttons=list([\n",
        "                            dict(count=1,\n",
        "                                 label=\"1m\",\n",
        "                                 step=\"month\",\n",
        "                                 stepmode=\"backward\"),\n",
        "                            dict(count=3,\n",
        "                                 label=\"3m\",\n",
        "                                 step=\"month\",\n",
        "                                 stepmode=\"backward\"),\n",
        "                            dict(count=6,\n",
        "                                 label=\"6m\",\n",
        "                                 step=\"month\",\n",
        "                                 stepmode=\"backward\"),\n",
        "                            dict(count=1,\n",
        "                                 label=\"1yr\",\n",
        "                                 step=\"year\",\n",
        "                                 stepmode=\"backward\"),\n",
        "                            dict(step=\"all\")\n",
        "                        ])\n",
        "                    ),\n",
        "                    rangeslider=dict(\n",
        "                        visible=False,\n",
        "                        thickness=0.05\n",
        "                    ),\n",
        "                    type=\"date\"),\n",
        "        yaxis1=dict(axis, **dict(domain=[0, 0.10], anchor='x1', title='New users<br>per category')),\n",
        "        yaxis2=dict(axis, **dict(domain=[0.12, 0.7], anchor='x1', title='New/Active/<br>Returning')),\n",
        "        yaxis3=dict(axis, **dict(domain=[0.705, 0.85], anchor='x1', hoverformat='.2f', title='Growth%')),\n",
        "        yaxis4=dict(axis, **dict(domain=[0.855, 1], anchor='x1', title='NR<br>Ratio')),\n",
        "        plot_bgcolor='rgba(228, 222, 239, 0.65)',\n",
        "        hovermode='closest'\n",
        "    )\n",
        "\n",
        "    data = [new1, organic, non_organic,\n",
        "            new2, active, returning,\n",
        "            growth,\n",
        "            NR_ratio]\n",
        "\n",
        "    return dict(data=data, layout=layout)\n",
        "\n",
        "  def retention_heatmap(self, df, figsize=(12, 6), type='val'):\n",
        "    \"\"\"\n",
        "    Function used to plot retention heatmaps.\n",
        "    \"\"\"\n",
        "    sns.set()\n",
        "\n",
        "    # used to set the number format (values vs percentages)\n",
        "    if type == 'val':\n",
        "        values_fmt = '.0f'\n",
        "    else:\n",
        "        values_fmt = '.0%'\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    h = sns.heatmap(df,\n",
        "                    cmap='Blues',\n",
        "                    annot=True,\n",
        "                    yticklabels=list(zip(df.index.get_level_values(0).strftime('%Y-%m-%d').values,\n",
        "                                         df.index.get_level_values(1))),\n",
        "                    annot_kws={'fontsize': 14},\n",
        "                    fmt=values_fmt)\n",
        "    plt.yticks(rotation=0, fontsize=14)\n",
        "    plt.xticks(rotation=0, fontsize=14)\n",
        "    plt.xlabel('\\nCohort Period', fontsize=16)\n",
        "    plt.ylabel('(Cohort, Cohort Size)\\n', fontsize=16)\n",
        "    plt.title('Retention', fontsize=20)\n",
        "    plt.show()\n",
        "\n",
        "    return h\n",
        "\n",
        "  def plot_user_flow(self, df, starting_step, n_steps=3, events_per_step=5, title='Sankey Diagram'):\n",
        "    \"\"\"\n",
        "    Function used to generate the sankey plot for user journeys.\n",
        "    \"\"\"\n",
        "    # transform raw events dataframe into  source:target pairs including node ids and count of each combination\n",
        "    label_list, colors_list, source_target_df = acquisition_class.sankey_df(df, starting_step, n_steps, events_per_step)\n",
        "\n",
        "    # creating the sankey diagram\n",
        "    data = dict(\n",
        "        type='sankey',\n",
        "        node=dict(\n",
        "            pad=20,\n",
        "            thickness=20,\n",
        "            color=colors_list,\n",
        "            line=dict(\n",
        "                color=\"black\",\n",
        "                width=0.5\n",
        "            ),\n",
        "            label=label_list\n",
        "        ),\n",
        "        link=dict(\n",
        "            source=source_target_df['source_id'].values.tolist(),\n",
        "            target=source_target_df['target_id'].values.tolist(),\n",
        "            value=source_target_df['count'].astype(int).values.tolist(),\n",
        "            hoverlabel=dict(\n",
        "                bgcolor='#C2C4C7')\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # set window width\n",
        "    if n_steps < 5:\n",
        "        width = None\n",
        "    else:\n",
        "        width = n_steps * 250\n",
        "\n",
        "    layout = dict(\n",
        "        height=600,\n",
        "        width=width,\n",
        "        margin=dict(t=30, l=0, r=0, b=30),\n",
        "        #         autosize=True,\n",
        "        title=title,\n",
        "        font=dict(\n",
        "            size=10\n",
        "        )\n",
        "    )\n",
        "\n",
        "    fig = dict(data=[data], layout=layout)\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbBJJN-CQZgR"
      },
      "source": [
        "#empty dataset with 150k rows\n",
        "df = pd.DataFrame({'user_id':0,\n",
        "                   'user_category':None,\n",
        "                   'event':None,\n",
        "                   'time':pd.NaT},\n",
        "                  index=list(range(150000)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "-JUxFpRXEWOt",
        "outputId": "56c73cc3-c871-4b1c-8b1e-f30aebe097f8"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_category</th>\n",
              "      <th>event</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id user_category event time\n",
              "0        0          None  None  NaT\n",
              "1        0          None  None  NaT\n",
              "2        0          None  None  NaT\n",
              "3        0          None  None  NaT\n",
              "4        0          None  None  NaT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz9MJTeWRuaZ"
      },
      "source": [
        "#generate 7k user_IDs randomly\n",
        "user_ids = np.arange(7000)+1\n",
        "\n",
        "#user categories: users who installed the app on their own are organic\n",
        "#and the users who installed it through the campaign, advertisements \n",
        "#or for rewards, are non-organic users.\n",
        "user_categories = ['organic','non-organic']\n",
        "\n",
        "#create events list \n",
        "events = ['install','signup','click_other_content',\n",
        "          'create_content','create_team','create_colab_content',\n",
        "          'post_content','post_colab_content','delete_content']\n",
        "\n",
        "#create a date range\n",
        "dates = pd.date_range(start='2019-01-01',end='2020-12-31', freq='H')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ydifXZSXr2F"
      },
      "source": [
        "#populate the generated values to the empty dataset\n",
        "df.user_id = df.user_id.apply(lambda user: random.choice(user_ids))\n",
        "\n",
        "#assign user category to each user randomly\n",
        "user_cat_dict = {user_id:random.choice(user_categories) for user_id in df.user_id.unique()}\n",
        "df.user_category = df.user_id.map(user_cat_dict)\n",
        "\n",
        "#populate event and time columns \n",
        "#by randomly applying values from events and dates lists\n",
        "df.event = df.event.apply(lambda event: random.choice(events))\n",
        "df.time = df.time.apply(lambda time: random.choice(dates))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "zWaSVM5IenoX",
        "outputId": "dc2b5a40-c715-4178-c0e7-f8b714b3a531"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_category</th>\n",
              "      <th>event</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2227</td>\n",
              "      <td>non-organic</td>\n",
              "      <td>create_team</td>\n",
              "      <td>2019-01-02 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>184</td>\n",
              "      <td>organic</td>\n",
              "      <td>signup</td>\n",
              "      <td>2019-11-10 19:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3930</td>\n",
              "      <td>non-organic</td>\n",
              "      <td>post_content</td>\n",
              "      <td>2019-01-29 20:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4731</td>\n",
              "      <td>organic</td>\n",
              "      <td>create_colab_content</td>\n",
              "      <td>2019-03-09 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4431</td>\n",
              "      <td>organic</td>\n",
              "      <td>post_colab_content</td>\n",
              "      <td>2019-05-08 01:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id user_category                 event                time\n",
              "0     2227   non-organic           create_team 2019-01-02 00:00:00\n",
              "1      184       organic                signup 2019-11-10 19:00:00\n",
              "2     3930   non-organic          post_content 2019-01-29 20:00:00\n",
              "3     4731       organic  create_colab_content 2019-03-09 00:00:00\n",
              "4     4431       organic    post_colab_content 2019-05-08 01:00:00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmHYLtSe77pX"
      },
      "source": [
        "acquisition_class = UserAcquisition()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "K8i32kDc-qL8",
        "outputId": "9c75cbed-0065-4f5a-9fff-eba705d6cda2"
      },
      "source": [
        "#Extracting acquisition time, user cohorts, events period\n",
        "acquisition_class.cohort_events_acquisition(df=df,event='install').head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_category</th>\n",
              "      <th>event</th>\n",
              "      <th>time</th>\n",
              "      <th>acquisition_time</th>\n",
              "      <th>cohort</th>\n",
              "      <th>event_period</th>\n",
              "      <th>user_active</th>\n",
              "      <th>plan_user_active</th>\n",
              "      <th>user_returns</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2806</td>\n",
              "      <td>non-organic</td>\n",
              "      <td>signup</td>\n",
              "      <td>2019-06-14 16:00:00</td>\n",
              "      <td>2019-01-20 02:00:00</td>\n",
              "      <td>2019-01-14</td>\n",
              "      <td>2019-06-10</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4687</td>\n",
              "      <td>non-organic</td>\n",
              "      <td>post_content</td>\n",
              "      <td>2019-10-05 11:00:00</td>\n",
              "      <td>2019-07-02 02:00:00</td>\n",
              "      <td>2019-07-01</td>\n",
              "      <td>2019-09-30</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6678</td>\n",
              "      <td>organic</td>\n",
              "      <td>delete_content</td>\n",
              "      <td>2020-10-18 09:00:00</td>\n",
              "      <td>2019-01-26 11:00:00</td>\n",
              "      <td>2019-01-21</td>\n",
              "      <td>2020-10-12</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5679</td>\n",
              "      <td>organic</td>\n",
              "      <td>signup</td>\n",
              "      <td>2020-10-07 19:00:00</td>\n",
              "      <td>2019-03-20 16:00:00</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>2020-10-05</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4113</td>\n",
              "      <td>non-organic</td>\n",
              "      <td>signup</td>\n",
              "      <td>2019-08-12 01:00:00</td>\n",
              "      <td>2019-07-06 21:00:00</td>\n",
              "      <td>2019-07-01</td>\n",
              "      <td>2019-08-12</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id user_category  ... plan_user_active user_returns\n",
              "0     2806   non-organic  ...             True         True\n",
              "1     4687   non-organic  ...             True         True\n",
              "2     6678       organic  ...             True         True\n",
              "3     5679       organic  ...             True         True\n",
              "4     4113   non-organic  ...             True         True\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I5r1IZqE-37h",
        "outputId": "cf51e16a-5122-4c5a-91a9-cb7077052ce9"
      },
      "source": [
        "#Activity statistics per period\n",
        "acquisition_class.users_per_period(df=df,\n",
        "                                   event='install',\n",
        "                                   user_category='user_category',\n",
        "                                   period='month')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>new_users</th>\n",
              "      <th>new_organic_users</th>\n",
              "      <th>new_non_organic_users</th>\n",
              "      <th>active_users</th>\n",
              "      <th>returning_users</th>\n",
              "      <th>w/w_growth</th>\n",
              "      <th>new/return_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>month</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01</th>\n",
              "      <td>650</td>\n",
              "      <td>342</td>\n",
              "      <td>308</td>\n",
              "      <td>650</td>\n",
              "      <td>0</td>\n",
              "      <td>nan%</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-02</th>\n",
              "      <td>589</td>\n",
              "      <td>298</td>\n",
              "      <td>291</td>\n",
              "      <td>964</td>\n",
              "      <td>375</td>\n",
              "      <td>-9.38%</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03</th>\n",
              "      <td>561</td>\n",
              "      <td>269</td>\n",
              "      <td>292</td>\n",
              "      <td>1313</td>\n",
              "      <td>752</td>\n",
              "      <td>-4.75%</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04</th>\n",
              "      <td>473</td>\n",
              "      <td>219</td>\n",
              "      <td>254</td>\n",
              "      <td>1471</td>\n",
              "      <td>998</td>\n",
              "      <td>-15.69%</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-05</th>\n",
              "      <td>431</td>\n",
              "      <td>206</td>\n",
              "      <td>225</td>\n",
              "      <td>1771</td>\n",
              "      <td>1340</td>\n",
              "      <td>-8.88%</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-06</th>\n",
              "      <td>372</td>\n",
              "      <td>174</td>\n",
              "      <td>198</td>\n",
              "      <td>2002</td>\n",
              "      <td>1630</td>\n",
              "      <td>-13.69%</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07</th>\n",
              "      <td>376</td>\n",
              "      <td>192</td>\n",
              "      <td>184</td>\n",
              "      <td>2214</td>\n",
              "      <td>1838</td>\n",
              "      <td>1.08%</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08</th>\n",
              "      <td>331</td>\n",
              "      <td>161</td>\n",
              "      <td>170</td>\n",
              "      <td>2381</td>\n",
              "      <td>2050</td>\n",
              "      <td>-11.97%</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09</th>\n",
              "      <td>294</td>\n",
              "      <td>144</td>\n",
              "      <td>150</td>\n",
              "      <td>2522</td>\n",
              "      <td>2228</td>\n",
              "      <td>-11.18%</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10</th>\n",
              "      <td>274</td>\n",
              "      <td>155</td>\n",
              "      <td>119</td>\n",
              "      <td>2685</td>\n",
              "      <td>2411</td>\n",
              "      <td>-6.80%</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11</th>\n",
              "      <td>253</td>\n",
              "      <td>125</td>\n",
              "      <td>128</td>\n",
              "      <td>2771</td>\n",
              "      <td>2518</td>\n",
              "      <td>-7.66%</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12</th>\n",
              "      <td>196</td>\n",
              "      <td>97</td>\n",
              "      <td>99</td>\n",
              "      <td>2901</td>\n",
              "      <td>2705</td>\n",
              "      <td>-22.53%</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01</th>\n",
              "      <td>229</td>\n",
              "      <td>131</td>\n",
              "      <td>98</td>\n",
              "      <td>3129</td>\n",
              "      <td>2900</td>\n",
              "      <td>16.84%</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02</th>\n",
              "      <td>178</td>\n",
              "      <td>91</td>\n",
              "      <td>87</td>\n",
              "      <td>3117</td>\n",
              "      <td>2939</td>\n",
              "      <td>-22.27%</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03</th>\n",
              "      <td>173</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "      <td>3340</td>\n",
              "      <td>3167</td>\n",
              "      <td>-2.81%</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04</th>\n",
              "      <td>160</td>\n",
              "      <td>72</td>\n",
              "      <td>88</td>\n",
              "      <td>3272</td>\n",
              "      <td>3112</td>\n",
              "      <td>-7.51%</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05</th>\n",
              "      <td>146</td>\n",
              "      <td>70</td>\n",
              "      <td>76</td>\n",
              "      <td>3421</td>\n",
              "      <td>3275</td>\n",
              "      <td>-8.75%</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06</th>\n",
              "      <td>104</td>\n",
              "      <td>53</td>\n",
              "      <td>51</td>\n",
              "      <td>3474</td>\n",
              "      <td>3370</td>\n",
              "      <td>-28.77%</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07</th>\n",
              "      <td>131</td>\n",
              "      <td>59</td>\n",
              "      <td>72</td>\n",
              "      <td>3600</td>\n",
              "      <td>3469</td>\n",
              "      <td>25.96%</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-08</th>\n",
              "      <td>96</td>\n",
              "      <td>46</td>\n",
              "      <td>50</td>\n",
              "      <td>3606</td>\n",
              "      <td>3510</td>\n",
              "      <td>-26.72%</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09</th>\n",
              "      <td>84</td>\n",
              "      <td>43</td>\n",
              "      <td>41</td>\n",
              "      <td>3640</td>\n",
              "      <td>3556</td>\n",
              "      <td>-12.50%</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10</th>\n",
              "      <td>93</td>\n",
              "      <td>39</td>\n",
              "      <td>54</td>\n",
              "      <td>3720</td>\n",
              "      <td>3627</td>\n",
              "      <td>10.71%</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-11</th>\n",
              "      <td>66</td>\n",
              "      <td>39</td>\n",
              "      <td>27</td>\n",
              "      <td>3688</td>\n",
              "      <td>3622</td>\n",
              "      <td>-29.03%</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12</th>\n",
              "      <td>66</td>\n",
              "      <td>32</td>\n",
              "      <td>34</td>\n",
              "      <td>3751</td>\n",
              "      <td>3685</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         new_users  new_organic_users  ...  w/w_growth  new/return_ratio\n",
              "month                                  ...                              \n",
              "2019-01        650                342  ...        nan%               nan\n",
              "2019-02        589                298  ...      -9.38%               1.6\n",
              "2019-03        561                269  ...      -4.75%               0.7\n",
              "2019-04        473                219  ...     -15.69%               0.5\n",
              "2019-05        431                206  ...      -8.88%               0.3\n",
              "2019-06        372                174  ...     -13.69%               0.2\n",
              "2019-07        376                192  ...       1.08%               0.2\n",
              "2019-08        331                161  ...     -11.97%               0.2\n",
              "2019-09        294                144  ...     -11.18%               0.1\n",
              "2019-10        274                155  ...      -6.80%               0.1\n",
              "2019-11        253                125  ...      -7.66%               0.1\n",
              "2019-12        196                 97  ...     -22.53%               0.1\n",
              "2020-01        229                131  ...      16.84%               0.1\n",
              "2020-02        178                 91  ...     -22.27%               0.1\n",
              "2020-03        173                 85  ...      -2.81%               0.1\n",
              "2020-04        160                 72  ...      -7.51%               0.1\n",
              "2020-05        146                 70  ...      -8.75%               0.0\n",
              "2020-06        104                 53  ...     -28.77%               0.0\n",
              "2020-07        131                 59  ...      25.96%               0.0\n",
              "2020-08         96                 46  ...     -26.72%               0.0\n",
              "2020-09         84                 43  ...     -12.50%               0.0\n",
              "2020-10         93                 39  ...      10.71%               0.0\n",
              "2020-11         66                 39  ...     -29.03%               0.0\n",
              "2020-12         66                 32  ...       0.00%               0.0\n",
              "\n",
              "[24 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1JbTN7Khnul"
      },
      "source": [
        "visualisations_class = Visualisations()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dtFymx3HtCh"
      },
      "source": [
        "from plotly.offline import iplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "2yk48qsKk7uI",
        "outputId": "b979c10e-e2ce-4fda-cab6-6a43ac434ce8"
      },
      "source": [
        "\"\"\"\n",
        "def browser_state():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML(\n",
        "      '''\n",
        "      <script source='/static/components/requirejs/require.js'></script>\n",
        "      <script>\n",
        "        requirejs.config{(\n",
        "          paths: {\n",
        "            base: '/static/base',\n",
        "            plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
        "          },\n",
        "        )};\n",
        "      </script>\n",
        "      '''))\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndef browser_state():\\n  import IPython\\n  display(IPython.core.display.HTML(\\n      '''\\n      <script source='/static/components/requirejs/require.js'></script>\\n      <script>\\n        requirejs.config{(\\n          paths: {\\n            base: '/static/base',\\n            plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\\n          },\\n        )};\\n      </script>\\n      '''))\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7_lBaStKbok"
      },
      "source": [
        "fig = visualisations_class.growth(df=df, event='install', \n",
        "                            user_category='user_category', period='month')\n",
        "iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWjjeaqA2OUS"
      },
      "source": [
        "Due to some plotly issue I am unable to plot graphs on colab, for now please plot graph through local python scripts, The other graphs can be plotted like this as well."
      ]
    }
  ]
}